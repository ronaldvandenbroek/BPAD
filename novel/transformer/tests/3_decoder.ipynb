{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../../..')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/implementing-the-transformer-decoder-from-scratch-in-tensorflow-and-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0.06260548 -1.6471055  -0.3378949  ...  0.9240057  -0.27485728\n",
      "    2.6387672 ]\n",
      "  [ 0.07485356 -1.6604608  -0.23512328 ...  0.8922469  -0.3129926\n",
      "    2.611713  ]\n",
      "  [ 0.04604615 -1.7444087  -0.17297083 ...  0.84704465 -0.30721706\n",
      "    2.5556507 ]\n",
      "  [-0.03552708 -1.8113804  -0.18145402 ...  0.7847883  -0.27733865\n",
      "    2.4996076 ]\n",
      "  [-0.08097387 -1.7682338  -0.21797003 ...  0.79161096 -0.25019947\n",
      "    2.4787252 ]]\n",
      "\n",
      " [[-0.35616663 -1.2868416  -0.15067959 ...  0.8755983  -0.3266152\n",
      "    2.0446782 ]\n",
      "  [-0.34073198 -1.2798744  -0.03461976 ...  0.8347163  -0.37158534\n",
      "    2.0095406 ]\n",
      "  [-0.3518471  -1.3700246   0.02117351 ...  0.7882521  -0.35765803\n",
      "    1.9454918 ]\n",
      "  [-0.42839566 -1.4445667   0.01271082 ...  0.7384284  -0.31553602\n",
      "    1.885753  ]\n",
      "  [-0.4674029  -1.3846922  -0.02591156 ...  0.73926467 -0.28766584\n",
      "    1.8653157 ]]\n",
      "\n",
      " [[ 0.02380196 -1.3434334  -0.24166185 ...  1.0920457  -0.41904947\n",
      "    2.2049973 ]\n",
      "  [ 0.05099506 -1.3603365  -0.10742862 ...  1.046522   -0.44279656\n",
      "    2.1827312 ]\n",
      "  [ 0.02956186 -1.4381143  -0.04410733 ...  0.9862853  -0.4191246\n",
      "    2.1262496 ]\n",
      "  [-0.04739742 -1.494424   -0.07618191 ...  0.9194623  -0.37004763\n",
      "    2.060684  ]\n",
      "  [-0.09032703 -1.4334434  -0.13147834 ...  0.89970297 -0.36291158\n",
      "    2.0129013 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.22810645 -1.2846372  -0.01127768 ...  0.9563605  -0.31793997\n",
      "    2.221088  ]\n",
      "  [-0.20730786 -1.2834338   0.12414329 ...  0.94691074 -0.37027654\n",
      "    2.1895487 ]\n",
      "  [-0.21410592 -1.355045    0.19266771 ...  0.90795326 -0.38281408\n",
      "    2.169122  ]\n",
      "  [-0.2656568  -1.41206     0.18471758 ...  0.857423   -0.36997798\n",
      "    2.1263125 ]\n",
      "  [-0.30553624 -1.3625301   0.14268985 ...  0.84011364 -0.35254902\n",
      "    2.0760484 ]]\n",
      "\n",
      " [[-0.22015108 -1.5478501  -0.56567127 ...  1.0216393  -0.22588535\n",
      "    2.318553  ]\n",
      "  [-0.19894394 -1.5581702  -0.47487715 ...  0.97881675 -0.25706875\n",
      "    2.2783754 ]\n",
      "  [-0.20234962 -1.6515828  -0.42505094 ...  0.9248573  -0.2507247\n",
      "    2.2491524 ]\n",
      "  [-0.26144418 -1.7389499  -0.42539394 ...  0.8785538  -0.23246074\n",
      "    2.2221355 ]\n",
      "  [-0.31779006 -1.7121664  -0.45467538 ...  0.8755403  -0.2166747\n",
      "    2.210493  ]]\n",
      "\n",
      " [[-0.11157299 -1.1459956  -0.27409828 ...  0.6098364  -0.15533413\n",
      "    2.5023074 ]\n",
      "  [-0.08091716 -1.1415197  -0.1340917  ...  0.5903457  -0.18708487\n",
      "    2.4684663 ]\n",
      "  [-0.07946625 -1.200833   -0.06363389 ...  0.5338782  -0.17329508\n",
      "    2.4220579 ]\n",
      "  [-0.14295332 -1.2501526  -0.09445947 ...  0.47797027 -0.13515292\n",
      "    2.3210578 ]\n",
      "  [-0.17939824 -1.2079754  -0.13608828 ...  0.4493717  -0.13010667\n",
      "    2.2538607 ]]], shape=(64, 5, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from numpy import random\n",
    "\n",
    "from novel.transformer.components.decoder import Decoder\n",
    "\n",
    "dec_vocab_size = 20  # Vocabulary size for the decoder\n",
    "input_seq_length = 5  # Maximum length of the input sequence\n",
    "h = 8  # Number of self-attention heads\n",
    "d_k = 64  # Dimensionality of the linearly projected queries and keys\n",
    "d_v = 64  # Dimensionality of the linearly projected values\n",
    "d_ff = 2048  # Dimensionality of the inner fully connected layer\n",
    "d_model = 512  # Dimensionality of the model sub-layers' outputs\n",
    "n = 6  # Number of layers in the decoder stack\n",
    "\n",
    "batch_size = 64  # Batch size from the training process\n",
    "dropout_rate = 0.1  # Frequency of dropping the input units in the dropout layers\n",
    "\n",
    "input_seq = random.random((batch_size, input_seq_length))\n",
    "enc_output = random.random((batch_size, input_seq_length, d_model))\n",
    "\n",
    "decoder = Decoder(dec_vocab_size, input_seq_length, h, d_k, d_v, d_model, d_ff, n, dropout_rate)\n",
    "print(decoder(input_seq, enc_output, None, True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rcvdb-thesis-bpad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
