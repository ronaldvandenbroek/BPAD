{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../../..')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/implementing-the-transformer-encoder-from-scratch-in-tensorflow-and-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 1.80655766e+00 -3.64059031e-01 -1.68190096e-02 ... -1.04179740e+00\n",
      "   -1.91739038e-01  2.43141556e+00]\n",
      "  [ 1.92515504e+00 -4.87700731e-01  6.69057667e-02 ... -4.03503418e-01\n",
      "    4.12621051e-01  2.67381477e+00]\n",
      "  [ 1.44447100e+00 -1.19622290e+00  5.38371265e-01 ... -1.49554396e+00\n",
      "    2.11584265e-03  2.49284697e+00]\n",
      "  [ 2.07780361e+00 -8.08755875e-01  1.36769563e-01 ... -1.17206454e+00\n",
      "    9.48180258e-01  2.33902025e+00]\n",
      "  [ 1.25449634e+00 -7.78167725e-01 -5.33378005e-01 ... -1.22565329e+00\n",
      "    8.00668538e-01  1.80049980e+00]]\n",
      "\n",
      " [[ 8.24024200e-01  1.17335284e+00  1.16610253e+00 ... -7.69325495e-01\n",
      "    3.96813840e-01  1.60396087e+00]\n",
      "  [ 1.38039041e+00  1.27384269e+00 -5.32875121e-01 ... -2.40187749e-01\n",
      "    5.88105977e-01  1.02606475e+00]\n",
      "  [ 1.73825949e-01 -6.22202575e-01 -1.07341655e-01 ... -1.39424467e+00\n",
      "    5.77196419e-01  1.31206644e+00]\n",
      "  [ 1.29620075e+00 -6.25063121e-01 -4.55254987e-02 ... -7.42903769e-01\n",
      "   -1.70770302e-01  1.28548074e+00]\n",
      "  [ 9.26235318e-01 -6.17526114e-01 -5.09200633e-01 ... -1.22818840e+00\n",
      "    2.08180740e-01  1.63415885e+00]]\n",
      "\n",
      " [[ 4.04630721e-01 -8.57174098e-01 -2.31435284e-01 ... -1.27966642e+00\n",
      "    1.00542475e-02  1.74527931e+00]\n",
      "  [ 1.97179949e+00 -1.12895243e-01  2.17197239e-02 ... -2.42186689e+00\n",
      "    3.38654876e-01  1.10594702e+00]\n",
      "  [ 1.84300923e+00 -2.18009159e-01 -6.98904181e-03 ... -1.19776750e+00\n",
      "   -5.00755496e-02  1.97933626e+00]\n",
      "  [ 1.48636484e+00 -6.61452353e-01  2.09008723e-01 ... -1.11048770e+00\n",
      "   -1.62879825e-01  1.22325969e+00]\n",
      "  [ 1.11799884e+00 -5.10730982e-01 -4.29364115e-01 ... -2.00621557e+00\n",
      "    4.58678275e-01  2.38828111e+00]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 1.29346597e+00 -2.30546594e-01 -4.49515611e-01 ... -1.75283998e-01\n",
      "    7.26005062e-02  7.88559258e-01]\n",
      "  [ 1.56333220e+00  4.59901690e-01  1.15945017e+00 ... -1.86020994e+00\n",
      "    8.29069912e-01  2.00965595e+00]\n",
      "  [ 2.21059990e+00 -3.32538128e-01 -1.97245717e-01 ... -7.38505244e-01\n",
      "    7.28614509e-01  1.62519681e+00]\n",
      "  [ 1.60085201e+00 -7.36832261e-01 -2.56037146e-01 ... -1.33902156e+00\n",
      "    3.41348886e-01  2.41284108e+00]\n",
      "  [ 1.72002542e+00  7.66317725e-01 -5.75866163e-01 ... -6.72641516e-01\n",
      "    8.64770293e-01  1.88594842e+00]]\n",
      "\n",
      " [[ 2.56132424e-01 -6.37003109e-02  1.12635456e-01 ... -8.85324657e-01\n",
      "    7.09229648e-01  1.95157242e+00]\n",
      "  [ 1.63630378e+00 -3.69180918e-01  9.23180580e-01 ... -1.54815400e+00\n",
      "   -1.04524344e-01  2.16707420e+00]\n",
      "  [ 6.45266891e-01  7.80667886e-02  4.37473863e-01 ... -5.02476037e-01\n",
      "    9.89208043e-01  1.07997239e+00]\n",
      "  [ 6.07714832e-01 -4.08633977e-01 -5.91829896e-01 ... -1.44276655e+00\n",
      "    7.50744045e-01  1.81594658e+00]\n",
      "  [ 1.40231907e+00 -5.04276931e-01 -1.01551116e+00 ... -8.01576734e-01\n",
      "    6.32166028e-01  1.58772385e+00]]\n",
      "\n",
      " [[ 1.47403657e+00 -1.30576968e+00 -4.26135600e-01 ... -8.57418776e-01\n",
      "    9.15844977e-01  2.88929749e+00]\n",
      "  [ 1.65606451e+00 -5.64295113e-01 -5.19254170e-02 ... -5.22284329e-01\n",
      "    3.56252223e-01  2.75670552e+00]\n",
      "  [ 1.40442848e+00 -7.35373020e-01 -7.14768618e-02 ... -9.32015121e-01\n",
      "    2.28202432e-01  2.28017044e+00]\n",
      "  [ 9.09944892e-01 -1.08203709e+00 -1.47981429e+00 ... -8.55671525e-01\n",
      "    1.16760261e-01  2.68680286e+00]\n",
      "  [-9.50848982e-02 -1.23873794e+00 -5.57649672e-01 ... -4.60445106e-01\n",
      "    1.11646213e-01  1.09689260e+00]]], shape=(64, 5, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from numpy import random\n",
    "from novel.transformer.components.encoder import Encoder\n",
    "\n",
    "enc_vocab_size = 20 # Vocabulary size for the encoder\n",
    "input_seq_length = 5  # Maximum length of the input sequence\n",
    "h = 8  # Number of self-attention heads\n",
    "d_k = 64  # Dimensionality of the linearly projected queries and keys\n",
    "d_v = 64  # Dimensionality of the linearly projected values\n",
    "d_ff = 2048  # Dimensionality of the inner fully connected layer\n",
    "d_model = 512  # Dimensionality of the model sub-layers' outputs\n",
    "n = 6  # Number of layers in the encoder stack\n",
    "\n",
    "batch_size = 64  # Batch size from the training process\n",
    "dropout_rate = 0.1  # Frequency of dropping the input units in the dropout layers\n",
    "\n",
    "input_seq = random.random((batch_size, input_seq_length))\n",
    "\n",
    "encoder = Encoder(enc_vocab_size, input_seq_length, h, d_k, d_v, d_model, d_ff, n, dropout_rate)\n",
    "print(encoder(input_seq, None, True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rcvdb-thesis-bpad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
