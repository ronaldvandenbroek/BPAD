{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "root_path = os.path.abspath('..')\n",
    "sys.path.insert(0, root_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils.fs import RESULTS_RAW_DIR\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes, mark_inset\n",
    "from utils.enums import Perspective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_run():\n",
    "    def is_numeric(input):\n",
    "        try:\n",
    "            float(input)\n",
    "            return True\n",
    "        except ValueError:\n",
    "            return False\n",
    "        \n",
    "    numeric_folders = [folder for folder in os.listdir(RESULTS_RAW_DIR) if is_numeric(folder) and os.path.isdir(os.path.join(RESULTS_RAW_DIR, folder))]\n",
    "\n",
    "    if numeric_folders:\n",
    "        highest_number = max(float(folder) for folder in numeric_folders)\n",
    "        print(f\"The latest run is: {highest_number}\")\n",
    "        return str(highest_number)\n",
    "    else:\n",
    "        print(\"No runs found.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_results(run_name):\n",
    "    run_path = os.path.join(RESULTS_RAW_DIR, run_name)\n",
    "    npy_files = [file for file in os.listdir(run_path) if file.endswith('.npy')]\n",
    "\n",
    "    loaded_data = {}\n",
    "\n",
    "    # Load each .npy file and use the file name (without extension) as the key\n",
    "    for npy_file in npy_files:\n",
    "        file_path = os.path.join(run_path, npy_file)\n",
    "        key = os.path.splitext(npy_file)[0]  # Get the file name without .npy extension\n",
    "        loaded_data[key] = np.load(file_path)\n",
    "\n",
    "        print(f\"{loaded_data[key].shape} \\t {key}\")\n",
    "\n",
    "    return loaded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_buckets(keys):\n",
    "    buckets = set()\n",
    "    for key in keys:\n",
    "        numbers = re.findall(r'\\d+', key)\n",
    "        buckets.update(map(int, numbers))\n",
    "    if len(buckets) > 0:\n",
    "        return sorted(buckets)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_run = get_latest_run()\n",
    "results = load_results(run_name=latest_run)\n",
    "bucket_lengths = get_buckets(results.keys())\n",
    "\n",
    "# '1726688270.265151'   0.05 with 0 noise, batch size 8\n",
    "# '1726683337.723001'   0.25 with 0 noise, batch size 8\n",
    "# '1726688845.1876202'  0.05 with 0.25 noise, batch size 8\n",
    "# '1726688947.9127235'  0.25 with 0.25 noise, batch size 8\n",
    "# '1726689265.3127506'  0.05 with 1 noise, batch size 8\n",
    "# '1726689364.887093'   0.25 with 1 noise, batch size 8\n",
    "# '1726746216.6401465'  0.05 with 1 noise, batch size 1\n",
    "# '1726746783.290876'   0.25 with 1 noise, batch size 1\n",
    "# '1727098666.0037918'  first attempt multi task\n",
    "\n",
    "# '1727360416.767745'  0.25 with 1 noise, batch size 2, bucketing, one-hot and min-max\n",
    "# '1727363555.4167004' 0.25 with 1 noise, batch size 2, bucketing, only min-max\n",
    "# '1727365180.6552784' 0.25 with 1 noise, batch size 2, bucketing, no scaling\n",
    "\n",
    "# '1727435814.7056985' 0.15 with 0.25 noise, batch size 2, no arrival-time and workload anomalies\n",
    "# '1727436294.3738086' 0.15 with 0.25 noise, batch size 2, with arrival-time and workload anomalies\n",
    "\n",
    "# '1727444617.510686' 0.15 with 0.25 noise, batch size 2, with arrival-time and workload anomalies, fixed casting bug\n",
    "# '1727363555.4167004' 0.15 with 0.25 noise, batch size 2, with arrival-time and workload anomalies, only min-max\n",
    "# '1727445103.0633998'\n",
    "\n",
    "\n",
    "# '1727977210.4493766' Word2Vec attempt only categorical, batch = 32, no bucketing, sum\n",
    "# '1727977426.604367' Word2Vec attempt only categorical, batch = 4, no bucketing, sum\n",
    "# '1727977637.8275452' Word2Vec attempt only categorical, batch = 4, with bucketing, sum\n",
    "\n",
    "# '1728490622.7945442' Word2Vec test\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the amount of anomalies of each type are present\n",
    "if bucket_lengths is not None:\n",
    "    print(np.sum(results['labels_DAE_trace_8'][:,0] == 1))\n",
    "    print(np.sum(results['labels_DAE_trace_8'][:,1] == 1))\n",
    "    print(np.sum(results['labels_DAE_trace_8'][:,2] == 1))\n",
    "    print(np.sum(results['labels_DAE_trace_8'][:,3] == 1))\n",
    "\n",
    "    print(len(results['labels_DAE_trace_8']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Loop over bucket lengths\n",
    "if bucket_lengths is None:\n",
    "    losses = results.get('losses_DAE')\n",
    "    plt.plot(losses, label=f'Single Bucket')\n",
    "else:\n",
    "    for bucket_nr in bucket_lengths:\n",
    "        # Construct the key\n",
    "        key = f'losses_DAE_{bucket_nr}'\n",
    "        \n",
    "        # Retrieve the corresponding losses\n",
    "        losses = results.get(key)\n",
    "        \n",
    "        # Plot the losses\n",
    "        if losses is not None:\n",
    "            plt.plot(losses, label=f'Bucket {bucket_nr}')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Batch Index')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Model Loss for Different Data Buckets')\n",
    "plt.legend()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Reconstruction Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(results, labels, perspective, level, bucket=None, zoom=[[11000,13000],[-0.05, 0.2]]):\n",
    "    def scatter_plot(ax, results, labels):\n",
    "        y_values = results\n",
    "        x_values = np.arange(len(results))\n",
    "        ax.scatter(x_values[labels == 0], y_values[labels == 0], c='grey', s=3, label='Normal Prefixes', zorder=1)\n",
    "        ax.scatter(x_values[labels == 1], y_values[labels == 1], c='red', s=3, label='Anomalous Prefixes', zorder=2)\n",
    "        ax.grid(True)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(15, 6))\n",
    "\n",
    "    labels = labels[:, perspective]\n",
    "    scatter_plot(ax, results, labels)\n",
    "    \n",
    "    perspective_name = Perspective.values()[perspective]\n",
    "\n",
    "    bucket_string = ''\n",
    "    if bucket is not None:\n",
    "        bucket_string = f'with bucket size {str(bucket)}'\n",
    "    plt.title(f'Error per Prefix on the {perspective_name} perspective at {level} level {bucket_string}')\n",
    "    plt.xlabel('Prefix Index')\n",
    "    plt.ylabel('Loss')\n",
    "    \n",
    "    if zoom:\n",
    "        axins = inset_axes(ax, width=\"60%\", height=\"60%\", loc='upper right')\n",
    "\n",
    "        scatter_plot(axins, results, labels)\n",
    "        axins.set_xlim(zoom[0])\n",
    "        axins.set_ylim(zoom[1])\n",
    "        _,_ = ax.indicate_inset_zoom(axins, edgecolor=\"black\", linewidth=3)\n",
    "\n",
    "    plt.xlabel('Batch Index')\n",
    "    plt.ylabel('Error')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()\n",
    "\n",
    "def bucket_plot_losses(results_name, labels_name, perspective, level, zoom=[[11000,13000],[-0.05, 0.2]]):\n",
    "    if bucket_lengths is None:\n",
    "        plot_losses(\n",
    "            results=results[f'{results_name}'], \n",
    "            labels=results[f'{labels_name}'], \n",
    "            perspective=perspective, level=level, bucket=None, zoom=zoom)       \n",
    "    else:\n",
    "        for bucket in bucket_lengths:\n",
    "            plot_losses(\n",
    "                results=results[f'{results_name}_{bucket}'], \n",
    "                labels=results[f'{labels_name}_{bucket}'], \n",
    "                perspective=perspective, level=level, bucket=bucket, zoom=zoom)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_plot_losses(\n",
    "    results_name='result_DAE_trace_Order', \n",
    "    labels_name='labels_DAE_trace',\n",
    "    perspective=Perspective.ORDER,\n",
    "    level='trace',\n",
    "    zoom=None)\n",
    "    # zoom=[[2000,3000],[-0.01, 0.05]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_plot_losses(\n",
    "    results_name='result_DAE_trace_Attribute', \n",
    "    labels_name='labels_DAE_trace',\n",
    "    perspective=Perspective.ATTRIBUTE,\n",
    "    level='trace',\n",
    "    zoom=None)\n",
    "    #zoom=[[2000,5000],[-0.01, 0.2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    bucket_plot_losses(\n",
    "        results_name='result_DAE_trace_Arrival Time', \n",
    "        labels_name='labels_DAE_trace',\n",
    "        perspective=Perspective.ARRIVAL_TIME,\n",
    "        level='trace',\n",
    "        zoom=None)\n",
    "        #zoom=[[2000,5000],[-0.01, 0.2]])\n",
    "except:\n",
    "    print('Data does not exist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    bucket_plot_losses(\n",
    "        results_name='result_DAE_trace_Workload', \n",
    "        labels_name='labels_DAE_trace',\n",
    "        perspective=Perspective.WORKLOAD,\n",
    "        level='trace',\n",
    "        zoom=None)\n",
    "        #zoom=[[2000,5000],[-0.01, 0.2]])\n",
    "except:\n",
    "    print('Data does not exist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bucket_plot_losses_event(results_name, labels_name, perspective, level, zoom=[[11000,13000],[-0.05, 0.2]], event_index=0):\n",
    "    if bucket_lengths is None:\n",
    "        plot_losses(\n",
    "            results=results[f'{results_name}'][:,event_index], \n",
    "            labels=results[f'{labels_name}'][:,event_index], \n",
    "            perspective=perspective, level=level, bucket=None, zoom=zoom)\n",
    "    else:      \n",
    "        for bucket in bucket_lengths:\n",
    "            plot_losses(\n",
    "                results=results[f'{results_name}_{bucket}'][:,event_index], \n",
    "                labels=results[f'{labels_name}_{bucket}'][:,event_index], \n",
    "                perspective=perspective, level=level, bucket=bucket, zoom=zoom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_plot_losses_event(\n",
    "    results_name='result_DAE_event_Order', \n",
    "    labels_name='labels_DAE_event',\n",
    "    perspective=Perspective.ORDER,\n",
    "    level='event',\n",
    "    # zoom=[[2000,3000],[-0.01, 0.05]],\n",
    "    zoom=None,\n",
    "    event_index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_plot_losses_event(\n",
    "    results_name='result_DAE_event_Order', \n",
    "    labels_name='labels_DAE_event',\n",
    "    perspective=Perspective.ORDER,\n",
    "    level='event',\n",
    "    # zoom=[[2000,3000],[-0.01, 0.05]],\n",
    "    zoom=None,\n",
    "    event_index=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_plot_losses_event(\n",
    "    results_name='result_DAE_event_Attribute', \n",
    "    labels_name='labels_DAE_event',\n",
    "    perspective=Perspective.ATTRIBUTE,\n",
    "    level='event',\n",
    "    # zoom=[[2000,3000],[-0.01, 0.05]],\n",
    "    zoom=None,\n",
    "    event_index=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    bucket_plot_losses_event(\n",
    "        results_name='result_DAE_event_Arrival Time', \n",
    "        labels_name='labels_DAE_event',\n",
    "        perspective=Perspective.ARRIVAL_TIME,\n",
    "        level='event',\n",
    "        zoom=[[2000,3000],[-0.01, 0.05]],\n",
    "        event_index=2)\n",
    "except:\n",
    "    print('Error, skipped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    bucket_plot_losses_event(\n",
    "        results_name='result_DAE_event_Workload', \n",
    "        labels_name='labels_DAE_event',\n",
    "        perspective=Perspective.WORKLOAD,\n",
    "        level='event',\n",
    "        zoom=[[2000,3000],[-0.01, 0.05]],\n",
    "        event_index=0)\n",
    "except:\n",
    "    print('Error: Skipped')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rcvdb-thesis-bpad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
